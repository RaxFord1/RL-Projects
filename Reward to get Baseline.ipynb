{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obs = 4, n_acts = 2\n"
     ]
    }
   ],
   "source": [
    "obs_dim = env.observation_space.shape[0]\n",
    "n_acts = env.action_space.n\n",
    "print(\"obs = {}, n_acts = {}\".format(obs_dim, n_acts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00114128, -0.01948678, -0.00073424,  0.04375321])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mpl(x, sizes, activation = tf.tanh, output_activation=None):\n",
    "\n",
    "    for size in sizes:\n",
    "        x = tf.layers.dense(x,units = size, activation = activation)\n",
    "    \n",
    "    return tf.layers.dense(x, units = sizes[-1], activation = output_activation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-e62237961afe>:4: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /home/raxford/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "#first layer of NN\n",
    "obs_ph = tf.placeholder(shape=(None, obs_dim), dtype=tf.float32)\n",
    "#creating NN\n",
    "logit = mpl(obs_ph, sizes = [32,64]+[n_acts])\n",
    "#array([[0.01685937, 0.00622761]], dtype=float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-c7ed40647be8>:1: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.random.categorical` instead.\n"
     ]
    }
   ],
   "source": [
    "max_action = tf.multinomial(logits=logit,num_samples=1)\n",
    "#array([[0]])\n",
    "action = tf.squeeze(max_action, axis=1)\n",
    "#array([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss\n",
    "weights_ph = tf.placeholder(shape=(None,), dtype = tf.float32)\n",
    "act_ph = tf.placeholder(shape=(None,), dtype = tf.int32)\n",
    "\n",
    "#one_hot taken actions\n",
    "action_masks = tf.one_hot(act_ph, n_acts)\n",
    "#array([[0., 1.]...], dtype=float32)\n",
    "\n",
    "#reward that will get from this point\n",
    "baseline_ph = tf.placeholder(shape=(None,), dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = baseline_ph - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logprob(a|s)\n",
    "log_probs = tf.reduce_sum(action_masks * tf.nn.log_softmax(logit), axis=1)\n",
    "#array([-0.6952652,...], dtype=float32)\n",
    "loss = -tf.reduce_mean(weights_ph* log_probs* baseline)\n",
    "#9.812662"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer\n",
    "train_op = tf.train.AdamOptimizer(learning_rate = 1e-2).minimize(loss)\n",
    "#loss minimizes :D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variables for initializing and using\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_action = sess.run(action, {obs_ph: obs.reshape(1,-1)})[0]\n",
    "#get element from array 0 or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_to_go(rews):\n",
    "    n = len(rews)\n",
    "    rtgs = np.zeros_like(rews)\n",
    "    for i in reversed(range(n)):\n",
    "        rtgs[i] = rews[i] + (rtgs[i+1] if i+1 < n else 0)\n",
    "    #returns [200. 199. ... 1.]\n",
    "    return rtgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LMAO I DONT KNOW HOW IT WORKS, BUT IT WORKS\n",
    "def reward_after(w):\n",
    "    n = len(w)\n",
    "    list2 = w.copy()\n",
    "    for i in range(n):\n",
    "        prev_el = w[i]\n",
    "        su = 0\n",
    "        for j in reversed(range(i)):\n",
    "            if prev_el >= w[j]:\n",
    "                break\n",
    "            su+=1\n",
    "            prev_el = w[j]\n",
    "        \n",
    "        list2[i]=su if su != 0 else 1\n",
    "    return list2\n",
    "#w[i]+=j WORK\n",
    "#w[i]=200-w[i] NOT WORKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ab-conc;:::\n",
      " [199 198 197 196 195 194 193 192 191 190 189 188 187 186 185 184 183 182\n",
      " 181 180 179 178 177 176 175 174 173 172 171 170 169 168 167 166 165 164\n",
      " 163 162 161 160 159 158 157 156 155 154 153 152 151 150 149 148 147 146\n",
      " 145 144 143 142 141 140 139 138 137 136 135 134 133 132 131 130 129 128\n",
      " 127 126 125 124 123 122 121 120 119 118 117 116 115 114 113 112 111 110\n",
      " 109 108 107 106 105 104 103 102 101 100  99  98  97  96  95  94  93  92\n",
      "  91  90  89  88  87  86  85  84  83  82  81  80  79  78  77  76  75  74\n",
      "  73  72  71  70  69  68  67  66  65  64  63  62  61  60  59  58  57  56\n",
      "  55  54  53  52  51  50  49  48  47  46  45  44  43  42  41  40  39  38\n",
      "  37  36  35  34  33  32  31  30  29  28  27  26  25  24  23  22  21  20\n",
      "  19  18  17  16  15  14  13  12  11  10   9   8   7   6   5   4   3   2\n",
      "   1   0  99  98  97  96  95  94  93  92  91  90  89  88  87  86  85  84\n",
      "  83  82  81  80  79  78  77  76  75  74  73  72  71  70  69  68  67  66\n",
      "  65  64  63  62  61  60  59  58  57  56  55  54  53  52  51  50  49  48\n",
      "  47  46  45  44  43  42  41  40  39  38  37  36  35  34  33  32  31  30\n",
      "  29  28  27  26  25  24  23  22  21  20  19  18  17  16  15  14  13  12\n",
      "  11  10   9   8   7   6   5   4   3   2   1   0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  1,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
       "       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
       "       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
       "       195, 196, 197, 198, 199,   1,   1,   2,   3,   4,   5,   6,   7,\n",
       "         8,   9,  10,  11,  12,  13,  14,  15,  16,  17,  18,  19,  20,\n",
       "        21,  22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,  33,\n",
       "        34,  35,  36,  37,  38,  39,  40,  41,  42,  43,  44,  45,  46,\n",
       "        47,  48,  49,  50,  51,  52,  53,  54,  55,  56,  57,  58,  59,\n",
       "        60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,  71,  72,\n",
       "        73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,  85,\n",
       "        86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
       "        99])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = []\n",
    "b = []\n",
    "for i in reversed(range(200)):\n",
    "    a.append(i)\n",
    "a = np.array(a)\n",
    "a = a.reshape(len(a))\n",
    "for i in reversed(range(100)):\n",
    "    b.append(i)\n",
    "b = np.array(b)\n",
    "b = b.reshape(len(b))\n",
    "ab = np.concatenate((a,b),axis=0)\n",
    "print(\"ab-conc;:::\\n\",ab)\n",
    "\n",
    "reward_after(ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(batch_size = 5000):\n",
    "    \n",
    "    batch_obs = []\n",
    "    batch_acts = []\n",
    "    batch_rets = []\n",
    "    batch_lens = []\n",
    "    batch_weights = [] #[200.0, 199.0, ... 1.0, 200.0, ... 1.0]\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    ep_rews = []\n",
    "    rendering_epoch = True\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        if rendering_epoch == True:\n",
    "            env.render() \n",
    "        batch_obs.append(obs.copy())\n",
    "        \n",
    "        act = sess.run(action, {obs_ph: obs.reshape(1,-1)})[0]\n",
    "        \n",
    "        obs, reward, done, _ = env.step(act)\n",
    "        \n",
    "        batch_acts.append(act)\n",
    "        ep_rews.append(reward)\n",
    "        \n",
    "        if done:\n",
    "            rendering_epoch = False\n",
    "            #recording everything!\n",
    "            ep_ret, ep_len = sum(ep_rews), len(ep_rews)\n",
    "            \n",
    "            batch_rets.append(ep_ret)\n",
    "            batch_lens.append(ep_len)\n",
    "            \n",
    "            # the weight for each logprob(a_t|s_t) is reward-to-go from t\n",
    "            batch_weights += list(reward_to_go(ep_rews))\n",
    "            \n",
    "            #reset vatiables\n",
    "            obs, done, ep_rews = env.reset(), False, []\n",
    "            \n",
    "            if len(batch_obs)>batch_size:\n",
    "                break\n",
    "    if np.mean(batch_lens)<200:\n",
    "        baseline = reward_after(batch_weights)\n",
    "        batch_loss, _ = sess.run([loss, train_op], {\n",
    "            obs_ph: batch_obs,\n",
    "            act_ph: batch_acts,\n",
    "            weights_ph: batch_weights,\n",
    "            baseline_ph: baseline\n",
    "        })\n",
    "    else:\n",
    "        batch_loss = 0\n",
    "    return batch_loss, batch_rets, batch_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#0, batch_loss: 108.468, batch_rets: 22.647, batch_lens: 22.647\n",
      "#1, batch_loss: 202.407, batch_rets: 31.516, batch_lens: 31.516\n",
      "#2, batch_loss: 307.435, batch_rets: 39.117, batch_lens: 39.117\n",
      "#3, batch_loss: 359.817, batch_rets: 43.164, batch_lens: 43.164\n",
      "#4, batch_loss: 825.101, batch_rets: 56.944, batch_lens: 56.944\n",
      "#5, batch_loss: 950.259, batch_rets: 66.303, batch_lens: 66.303\n",
      "#6, batch_loss: 794.350, batch_rets: 60.578, batch_lens: 60.578\n",
      "#7, batch_loss: 1349.886, batch_rets: 78.781, batch_lens: 78.781\n",
      "#8, batch_loss: 1702.514, batch_rets: 80.968, batch_lens: 80.968\n",
      "#9, batch_loss: 1887.283, batch_rets: 89.035, batch_lens: 89.035\n",
      "#10, batch_loss: 1844.193, batch_rets: 94.528, batch_lens: 94.528\n",
      "#11, batch_loss: 2387.523, batch_rets: 117.047, batch_lens: 117.047\n",
      "#12, batch_loss: 2417.651, batch_rets: 114.622, batch_lens: 114.622\n",
      "#13, batch_loss: 2952.917, batch_rets: 135.541, batch_lens: 135.541\n",
      "#14, batch_loss: 2597.264, batch_rets: 139.333, batch_lens: 139.333\n",
      "#15, batch_loss: 2824.636, batch_rets: 134.105, batch_lens: 134.105\n",
      "#16, batch_loss: 2872.314, batch_rets: 149.529, batch_lens: 149.529\n",
      "#17, batch_loss: 2798.329, batch_rets: 152.647, batch_lens: 152.647\n",
      "#18, batch_loss: 2586.124, batch_rets: 146.086, batch_lens: 146.086\n",
      "#19, batch_loss: 2333.993, batch_rets: 149.853, batch_lens: 149.853\n",
      "#20, batch_loss: 1771.632, batch_rets: 120.214, batch_lens: 120.214\n",
      "#21, batch_loss: 2022.234, batch_rets: 132.949, batch_lens: 132.949\n",
      "#22, batch_loss: 2035.943, batch_rets: 139.917, batch_lens: 139.917\n",
      "#23, batch_loss: 2625.373, batch_rets: 170.267, batch_lens: 170.267\n",
      "#24, batch_loss: 2681.970, batch_rets: 172.862, batch_lens: 172.862\n",
      "#25, batch_loss: 3049.962, batch_rets: 189.926, batch_lens: 189.926\n",
      "#26, batch_loss: 2887.103, batch_rets: 183.000, batch_lens: 183.000\n",
      "#27, batch_loss: 3110.775, batch_rets: 195.000, batch_lens: 195.000\n",
      "#28, batch_loss: 3146.359, batch_rets: 196.769, batch_lens: 196.769\n",
      "#29, batch_loss: 2954.517, batch_rets: 189.519, batch_lens: 189.519\n",
      "#30, batch_loss: 2983.203, batch_rets: 192.556, batch_lens: 192.556\n",
      "#31, batch_loss: 2994.256, batch_rets: 185.815, batch_lens: 185.815\n",
      "#32, batch_loss: 2893.622, batch_rets: 193.615, batch_lens: 193.615\n",
      "#33, batch_loss: 3013.595, batch_rets: 192.962, batch_lens: 192.962\n",
      "#34, batch_loss: 2884.476, batch_rets: 185.704, batch_lens: 185.704\n",
      "#35, batch_loss: 2865.960, batch_rets: 191.407, batch_lens: 191.407\n",
      "#36, batch_loss: 2857.037, batch_rets: 194.077, batch_lens: 194.077\n",
      "#37, batch_loss: 3000.219, batch_rets: 196.038, batch_lens: 196.038\n",
      "#38, batch_loss: 2933.454, batch_rets: 194.577, batch_lens: 194.577\n",
      "#39, batch_loss: 2998.466, batch_rets: 191.000, batch_lens: 191.000\n",
      "#40, batch_loss: 2974.324, batch_rets: 196.115, batch_lens: 196.115\n",
      "#41, batch_loss: 0.000, batch_rets: 200.000, batch_lens: 200.000\n"
     ]
    }
   ],
   "source": [
    "for i in range(500):\n",
    "    batch_loss, batch_rets, batch_lens = train_one_epoch()\n",
    "    print(\"#%i, batch_loss: %.3f, batch_rets: %.3f, batch_lens: %.3f\" \\\n",
    "          %(i, batch_loss, np.mean(batch_rets), np.mean(batch_lens)))\n",
    "    if batch_loss == 0:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_episode():\n",
    "    \n",
    "    rewards = 0\n",
    "    obs = env.reset()\n",
    "    while True:\n",
    "        env.render()\n",
    "        act = sess.run(action, {obs_ph: obs.reshape(1,-1)})[0]\n",
    "        obs, reward, is_done, _ = env.step(act)\n",
    "        rewards += reward\n",
    "        #if is_done or rewards >200:\n",
    "         #   break\n",
    "    return rewards    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(play_episode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum = 8\n",
    "for i in range(8):\n",
    "    print(i)\n",
    "    sum+=i\n",
    "sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
